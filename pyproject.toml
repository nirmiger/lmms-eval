[tool.black]
line-length = 240

[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "lmms_eval"
version = "0.5.0"
authors = [
    { name = "LMMMs-Lab Evaluation Team", email = "lmms-lab@outlook.com" },
]
description = "A framework for evaluating large multi-modality language models"
readme = "README.md"
license = "MIT"
license-files = ["LICENSE"]
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
]
requires-python = ">=3.9"
dependencies = [
    "accelerate>=0.29.1",
    "black>=24.1.0",
    "isort>=5.13.2",
    "datasets>=2.19.0",
    "evaluate>=0.4.0",
    "httpx==0.23.3",
    "jsonlines",
    "numexpr",
    "numpy==1.26.4",
    "peft>=0.2.0",
    "pybind11>=2.6.2",
    "pytablewriter",
    "sacrebleu>=1.5.0",
    "scikit-learn>=0.24.1",
    "sqlitedict==2.1.0",
    "torch>=2.1.0", # to enable sdpa mode for running 34B model on one 80GB GPU
    "torchvision>=0.16.0",
    "timm",
    "einops",
    "ftfy",
    "openai",
    "opencv-python-headless",
    "av<16.0.0",
    "hf_transfer",
    "nltk",
    "sentencepiece",
    "yt-dlp",
    "pycocoevalcap",
    "tqdm-multiprocess",
    "transformers>=4.39.2",
    "transformers-stream-generator",
    "zstandard",
    "pillow",
    "pyyaml",
    "sympy",
    "latex2sympy2",
    "mpmath",
    "Jinja2",
    "openpyxl",
    "loguru",
    "hf_transfer",
    "tenacity==8.3.0",
    "wandb>=0.16.0",
    "tiktoken",
    "pre-commit",
    "pydantic",
    "packaging",
    #"decord; platform_system != 'Darwin'", # Decord is not available for aarch64 as wheel, need to build from source but for now not needed!
    #"eva-decord; platform_system == 'Darwin'",
    "zss",
    "protobuf",
    "sentence_transformers",
    "python-dotenv",
    "qwen-vl-utils>=0.0.14",
]

[project.optional-dependencies]
audio = [
    "more-itertools",
    "editdistance",
    "zhconv",
    "librosa",
    "soundfile"
]
metrics = [
    "pywsd",
    "spacy",
    "anls",
    "rouge",
    "capture_metric",
    "Levenshtein",
]
gemini = [
    "google-generativeai",
]
reka = [
    "httpx==0.23.3",
    "reka-api",
]
qwen = [
    "decord",
    "qwen_vl_utils",
]
emu3 = [
    "torch==2.2.1",
    "transformers==4.44.0",
    "tiktoken==0.6.0",
    "flash-attn==2.5.7",
    "pillow",
]
emu3_5 = [
    "pillow>=9.0.0",
    "numpy>=1.21.0",
    "tqdm>=4.64.0",
    "protobuf>=3.20.0",
    "tiktoken>=0.12.0",
    "imageio==2.37.0",
    "imageio-ffmpeg==0.6.0",
    "omegaconf==2.3.0",
    "transformers==4.48.2",
    "accelerate>=0.20.0",
    "torchvision>=0.15.0",
    #"torchaudio>=2.0.0",
    #"torch>=2.6.0",
]
mmsearch = [
    "playwright",
    "requests",
    "matplotlib",
    "duckduckgo_search",
    "langchain",
    "langchain-community",
    "beautifulsoup4",
    "FlagEmbedding",
    "rouge",
]
# Benchmark-specific dependencies
ocrbench_v2 = [
    "pandas>=2.0.0",
    "distance>=0.1.3",
    "apted>=1.0.3",
    "lxml>=4.9.0",
    "jieba>=0.42.1",
    "Polygon3>=3.0.9",
    "ipdb>=0.13.13",
    "editdistance>=0.6.0",
    "Levenshtein>=0.21.0",
]

[tool.setuptools.packages.find]
include = ["lmms_eval*"]
exclude = [
    "assets*",
    "benchmark*",
    "docs",
    "dist*",
    "playground*",
    "scripts*",
    "tests*",
    "checkpoints*",
    "project_checkpoints*",
    "debug_checkpoints*",
    "mlx_configs*",
    "wandb*",
    "notebooks*",
    "logs*",
]

[tool.wheel]
exclude = [
    "assets*",
    "benchmark*",
    "docs",
    "dist*",
    "playground*",
    "scripts*",
    "tests*",
    "checkpoints*",
    "project_checkpoints*",
    "debug_checkpoints*",
    "mlx_configs*",
    "wandb*",
    "notebooks*",
    "logs*",
]

[project.scripts]
lmms-eval = "lmms_eval.__main__:cli_evaluate"

[project.urls]
Homepage = "https://lmms-lab.github.io"
Repository = "https://github.com/EvolvingLMMs-Lab/lmms-eval"
